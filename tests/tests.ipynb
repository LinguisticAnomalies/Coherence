{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/NETID/xuweizhe/anaconda3/envs/coherencepip/lib/python3.9/site-packages/semvecpy/vectors/semvec_utils.py:5: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n",
      "/home/NETID/xuweizhe/anaconda3/envs/coherencepip/lib/python3.9/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "06/14/2024 17:04:01 - INFO - numba.cuda.cudadrv.driver -   init\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '/edata/coherencenotebook/coherencecalculator/src')\n",
    "from coherencecalculator.pipelines.timeseries import timeseries\n",
    "from coherencecalculator.pipelines.features import features\n",
    "from coherencecalculator.pipelines.tardis import tardis\n",
    "from coherencecalculator.pipelines.agg import agg\n",
    "from coherencecalculator.tools.vecloader import VecLoader\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vectors...\n",
      "300   REAL\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5693d24a514c4f6282ade5a5385c7ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2417831755 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "06/14/2024 17:08:41 - INFO - sentence_transformers.SentenceTransformer -   Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "Some weights of the model checkpoint at voidism/diffcse-bert-base-uncased-sts were not used when initializing BertModel: ['aux_bert.embeddings.LayerNorm.bias', 'aux_bert.encoder.layer.0.intermediate.dense.weight', 'aux_bert.encoder.layer.11.attention.self.query.weight', 'generator.distilbert.transformer.layer.5.attention.q_lin.bias', 'aux_bert.encoder.layer.7.attention.self.query.bias', 'lm_head.transform.LayerNorm.bias', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.attention.self.key.bias', 'generator.distilbert.transformer.layer.1.attention.v_lin.weight', 'generator.distilbert.transformer.layer.4.attention.q_lin.weight', 'generator.distilbert.transformer.layer.1.attention.q_lin.weight', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.attention.self.value.bias', 'generator.vocab_transform.weight', 'generator.distilbert.transformer.layer.2.sa_layer_norm.weight', 'generator.distilbert.transformer.layer.4.attention.k_lin.bias', 'generator.distilbert.embeddings.LayerNorm.weight', 'aux_bert.encoder.layer.5.output.LayerNorm.bias', 'generator.distilbert.transformer.layer.4.output_layer_norm.weight', 'generator.distilbert.transformer.layer.5.attention.k_lin.weight', 'aux_bert.encoder.layer.8.output.dense.weight', 'aux_bert.encoder.layer.9.attention.output.dense.weight', 'aux_bert.encoder.layer.7.attention.self.value.weight', 'generator.distilbert.embeddings.position_embeddings.weight', 'generator.distilbert.transformer.layer.5.output_layer_norm.bias', 'aux_bert.encoder.layer.1.attention.self.key.weight', 'generator.distilbert.transformer.layer.4.attention.out_lin.weight', 'generator.distilbert.transformer.layer.4.ffn.lin2.weight', 'aux_bert.encoder.layer.5.intermediate.dense.bias', 'generator.distilbert.transformer.layer.5.attention.v_lin.bias', 'aux_bert.encoder.layer.0.attention.self.value.weight', 'lm_head.bias', 'aux_bert.encoder.layer.9.attention.output.dense.bias', 'mlp.net.1.weight', 'generator.distilbert.transformer.layer.5.ffn.lin1.bias', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.attention.self.key.weight', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.bias', 'aux_bert.embeddings.token_type_embeddings.weight', 'aux_bert.encoder.layer.1.attention.self.query.weight', 'generator.distilbert.embeddings.word_embeddings.weight', 'aux_bert.encoder.layer.3.output.LayerNorm.weight', 'mlp.net.1.num_batches_tracked', 'generator.distilbert.transformer.layer.1.attention.k_lin.weight', 'generator.distilbert.transformer.layer.3.attention.q_lin.bias', 'aux_bert.encoder.layer.2.output.dense.weight', 'generator.distilbert.transformer.layer.1.output_layer_norm.bias', 'aux_bert.encoder.layer.9.output.dense.weight', 'aux_bert.encoder.layer.1.output.dense.weight', 'aux_bert.encoder.layer.6.attention.self.key.weight', 'generator.distilbert.transformer.layer.1.sa_layer_norm.bias', 'generator.distilbert.transformer.layer.0.attention.k_lin.bias', 'generator.distilbert.transformer.layer.4.output_layer_norm.bias', 'generator.distilbert.transformer.layer.1.attention.k_lin.bias', 'aux_bert.encoder.layer.4.attention.self.key.bias', 'aux_bert.encoder.layer.3.output.dense.weight', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.bias', 'mlp.net.4.running_var', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.self.key.weight', 'generator.distilbert.transformer.layer.0.attention.q_lin.weight', 'generator.distilbert.transformer.layer.5.ffn.lin1.weight', 'aux_bert.encoder.layer.11.attention.output.dense.bias', 'aux_bert.encoder.layer.10.attention.self.query.bias', 'aux_bert.encoder.layer.8.attention.self.value.bias', 'aux_bert.encoder.layer.8.attention.self.query.weight', 'aux_bert.encoder.layer.3.output.dense.bias', 'generator.distilbert.transformer.layer.3.attention.q_lin.weight', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.output.dense.weight', 'aux_bert.encoder.layer.4.output.dense.bias', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.output.dense.bias', 'aux_bert.encoder.layer.10.attention.self.value.weight', 'aux_bert.encoder.layer.1.attention.self.query.bias', 'generator.distilbert.transformer.layer.5.ffn.lin2.bias', 'generator.distilbert.transformer.layer.0.ffn.lin2.bias', 'aux_bert.encoder.layer.4.attention.output.dense.bias', 'aux_bert.encoder.layer.0.attention.output.dense.weight', 'aux_bert.encoder.layer.6.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.attention.self.key.bias', 'aux_bert.encoder.layer.6.intermediate.dense.bias', 'generator.distilbert.transformer.layer.2.attention.out_lin.bias', 'aux_bert.encoder.layer.10.attention.output.dense.weight', 'aux_bert.encoder.layer.11.output.dense.weight', 'aux_bert.encoder.layer.6.attention.self.value.weight', 'generator.distilbert.transformer.layer.5.attention.q_lin.weight', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.output.LayerNorm.weight', 'lm_head.transform.dense.bias', 'aux_bert.encoder.layer.10.output.dense.weight', 'lm_head.transform.LayerNorm.weight', 'aux_bert.encoder.layer.9.output.LayerNorm.bias', 'generator.distilbert.transformer.layer.1.ffn.lin2.bias', 'aux_bert.encoder.layer.9.output.dense.bias', 'generator.distilbert.transformer.layer.2.ffn.lin1.bias', 'aux_bert.encoder.layer.7.output.dense.weight', 'aux_bert.encoder.layer.11.attention.output.dense.weight', 'aux_bert.encoder.layer.5.attention.output.dense.weight', 'aux_bert.encoder.layer.11.attention.self.value.weight', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.attention.self.value.bias', 'aux_bert.encoder.layer.4.output.dense.weight', 'aux_bert.encoder.layer.8.output.dense.bias', 'aux_bert.encoder.layer.1.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.output.dense.weight', 'aux_bert.encoder.layer.11.attention.self.key.weight', 'aux_bert.encoder.layer.9.attention.self.key.weight', 'generator.distilbert.transformer.layer.5.sa_layer_norm.weight', 'generator.vocab_projector.bias', 'generator.distilbert.transformer.layer.3.ffn.lin2.weight', 'aux_bert.encoder.layer.5.attention.self.key.bias', 'aux_bert.encoder.layer.10.attention.self.query.weight', 'aux_bert.encoder.layer.10.attention.self.value.bias', 'generator.distilbert.transformer.layer.4.attention.out_lin.bias', 'aux_bert.encoder.layer.4.attention.self.key.weight', 'aux_bert.encoder.layer.4.attention.self.value.weight', 'aux_bert.encoder.layer.5.attention.output.dense.bias', 'generator.distilbert.transformer.layer.0.ffn.lin2.weight', 'generator.distilbert.transformer.layer.0.attention.v_lin.bias', 'lm_head.transform.dense.weight', 'aux_bert.encoder.layer.1.attention.output.dense.weight', 'aux_bert.encoder.layer.11.attention.self.query.bias', 'generator.distilbert.transformer.layer.2.output_layer_norm.weight', 'generator.distilbert.transformer.layer.2.attention.k_lin.weight', 'aux_bert.encoder.layer.7.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.self.key.bias', 'generator.distilbert.transformer.layer.2.ffn.lin2.bias', 'aux_bert.encoder.layer.11.intermediate.dense.bias', 'aux_bert.encoder.layer.2.attention.self.value.weight', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.attention.self.value.bias', 'generator.distilbert.transformer.layer.3.ffn.lin1.weight', 'generator.distilbert.transformer.layer.5.ffn.lin2.weight', 'aux_bert.encoder.layer.1.attention.self.value.bias', 'aux_bert.encoder.layer.9.attention.self.query.weight', 'aux_bert.encoder.layer.0.output.dense.bias', 'generator.distilbert.transformer.layer.2.sa_layer_norm.bias', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.attention.self.key.bias', 'generator.distilbert.transformer.layer.4.sa_layer_norm.bias', 'aux_bert.encoder.layer.3.attention.output.dense.bias', 'mlp.net.4.running_mean', 'aux_bert.encoder.layer.0.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.attention.output.dense.bias', 'aux_bert.encoder.layer.6.output.dense.weight', 'aux_bert.encoder.layer.8.attention.self.query.bias', 'generator.vocab_transform.bias', 'aux_bert.encoder.layer.0.attention.self.key.bias', 'mlp.net.1.running_var', 'generator.distilbert.transformer.layer.3.attention.out_lin.weight', 'generator.distilbert.transformer.layer.1.attention.v_lin.bias', 'generator.distilbert.transformer.layer.0.attention.k_lin.weight', 'generator.distilbert.transformer.layer.1.output_layer_norm.weight', 'generator.distilbert.transformer.layer.2.attention.v_lin.weight', 'aux_bert.encoder.layer.2.attention.self.value.bias', 'aux_bert.encoder.layer.3.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.attention.self.value.bias', 'aux_bert.encoder.layer.9.attention.self.value.weight', 'generator.distilbert.transformer.layer.2.attention.k_lin.bias', 'aux_bert.encoder.layer.11.attention.self.key.bias', 'generator.distilbert.transformer.layer.1.ffn.lin1.bias', 'aux_bert.encoder.layer.9.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.attention.output.dense.weight', 'mlp.net.1.bias', 'generator.distilbert.transformer.layer.5.attention.v_lin.weight', 'generator.distilbert.transformer.layer.0.attention.out_lin.weight', 'aux_bert.encoder.layer.7.attention.self.value.bias', 'mlp.net.1.running_mean', 'generator.distilbert.transformer.layer.2.attention.q_lin.bias', 'aux_bert.encoder.layer.6.output.dense.bias', 'generator.distilbert.transformer.layer.3.attention.k_lin.bias', 'generator.distilbert.transformer.layer.5.attention.out_lin.bias', 'aux_bert.encoder.layer.2.intermediate.dense.bias', 'generator.distilbert.transformer.layer.0.sa_layer_norm.weight', 'aux_bert.encoder.layer.10.intermediate.dense.weight', 'generator.distilbert.transformer.layer.3.ffn.lin1.bias', 'generator.distilbert.transformer.layer.4.attention.v_lin.bias', 'generator.vocab_layer_norm.bias', 'aux_bert.encoder.layer.2.attention.self.query.weight', 'aux_bert.encoder.layer.8.attention.self.value.weight', 'generator.distilbert.transformer.layer.1.attention.out_lin.bias', 'generator.distilbert.embeddings.LayerNorm.bias', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.output.dense.bias', 'aux_bert.encoder.layer.2.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.attention.self.query.weight', 'aux_bert.embeddings.LayerNorm.weight', 'aux_bert.embeddings.position_ids', 'aux_bert.encoder.layer.0.intermediate.dense.bias', 'generator.distilbert.transformer.layer.0.output_layer_norm.weight', 'aux_bert.encoder.layer.11.output.dense.bias', 'aux_bert.embeddings.word_embeddings.weight', 'generator.distilbert.transformer.layer.0.attention.q_lin.bias', 'aux_bert.encoder.layer.1.attention.output.dense.bias', 'aux_bert.encoder.layer.11.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.output.dense.bias', 'generator.distilbert.transformer.layer.1.ffn.lin1.weight', 'aux_bert.encoder.layer.7.intermediate.dense.bias', 'aux_bert.encoder.layer.2.attention.output.dense.bias', 'generator.distilbert.transformer.layer.2.ffn.lin2.weight', 'aux_bert.encoder.layer.4.attention.self.query.bias', 'aux_bert.encoder.layer.1.intermediate.dense.weight', 'aux_bert.encoder.layer.3.attention.self.query.weight', 'aux_bert.encoder.layer.9.intermediate.dense.weight', 'aux_bert.encoder.layer.4.intermediate.dense.bias', 'generator.distilbert.transformer.layer.1.ffn.lin2.weight', 'aux_bert.encoder.layer.1.attention.self.value.weight', 'generator.distilbert.transformer.layer.2.attention.q_lin.weight', 'mlp.net.4.num_batches_tracked', 'aux_bert.encoder.layer.9.attention.self.key.bias', 'generator.distilbert.transformer.layer.3.sa_layer_norm.weight', 'mlp.net.0.weight', 'aux_bert.encoder.layer.5.intermediate.dense.weight', 'aux_bert.encoder.layer.4.intermediate.dense.weight', 'generator.distilbert.transformer.layer.4.ffn.lin1.weight', 'aux_bert.encoder.layer.4.attention.output.dense.weight', 'aux_bert.encoder.layer.1.attention.self.key.bias', 'generator.distilbert.transformer.layer.3.attention.out_lin.bias', 'aux_bert.encoder.layer.0.attention.self.query.weight', 'generator.distilbert.transformer.layer.2.attention.v_lin.bias', 'aux_bert.encoder.layer.2.output.dense.bias', 'generator.distilbert.transformer.layer.2.ffn.lin1.weight', 'aux_bert.encoder.layer.10.attention.output.dense.bias', 'aux_bert.encoder.layer.10.attention.self.key.weight', 'aux_bert.encoder.layer.0.attention.self.key.weight', 'aux_bert.encoder.layer.10.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.intermediate.dense.weight', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.output.LayerNorm.weight', 'generator.distilbert.transformer.layer.0.ffn.lin1.bias', 'generator.distilbert.transformer.layer.4.ffn.lin1.bias', 'aux_bert.encoder.layer.8.intermediate.dense.bias', 'aux_bert.encoder.layer.7.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.intermediate.dense.weight', 'aux_bert.encoder.layer.4.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.attention.self.query.weight', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.bias', 'generator.distilbert.transformer.layer.4.sa_layer_norm.weight', 'generator.distilbert.transformer.layer.4.attention.q_lin.bias', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.weight', 'generator.distilbert.transformer.layer.1.sa_layer_norm.weight', 'aux_bert.encoder.layer.0.attention.self.value.bias', 'aux_bert.encoder.layer.0.attention.output.dense.bias', 'aux_bert.encoder.layer.9.attention.self.query.bias', 'generator.distilbert.transformer.layer.3.sa_layer_norm.bias', 'aux_bert.encoder.layer.0.attention.self.query.bias', 'generator.distilbert.transformer.layer.4.attention.v_lin.weight', 'aux_bert.encoder.layer.6.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.output.dense.bias', 'generator.distilbert.transformer.layer.3.attention.v_lin.bias', 'generator.distilbert.transformer.layer.4.attention.k_lin.weight', 'aux_bert.encoder.layer.5.attention.self.key.weight', 'aux_bert.encoder.layer.6.attention.output.dense.weight', 'generator.distilbert.transformer.layer.2.output_layer_norm.bias', 'aux_bert.encoder.layer.8.intermediate.dense.weight', 'generator.distilbert.transformer.layer.5.attention.out_lin.weight', 'aux_bert.encoder.layer.2.attention.self.query.bias', 'aux_bert.encoder.layer.5.output.dense.bias', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.attention.self.query.bias', 'generator.vocab_layer_norm.weight', 'aux_bert.encoder.layer.5.attention.self.value.weight', 'aux_bert.encoder.layer.8.attention.output.dense.weight', 'generator.distilbert.transformer.layer.3.ffn.lin2.bias', 'generator.distilbert.transformer.layer.0.attention.out_lin.bias', 'aux_bert.encoder.layer.3.intermediate.dense.bias', 'aux_bert.encoder.layer.8.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.attention.self.value.bias', 'aux_bert.encoder.layer.5.attention.self.query.bias', 'aux_bert.encoder.layer.2.attention.output.dense.weight', 'generator.distilbert.transformer.layer.5.output_layer_norm.weight', 'generator.distilbert.transformer.layer.5.attention.k_lin.bias', 'aux_bert.encoder.layer.3.attention.self.key.weight', 'aux_bert.encoder.layer.1.intermediate.dense.bias', 'generator.distilbert.transformer.layer.1.attention.out_lin.weight', 'aux_bert.encoder.layer.2.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.attention.self.query.bias', 'lm_head.decoder.weight', 'generator.distilbert.transformer.layer.3.attention.k_lin.weight', 'aux_bert.encoder.layer.6.attention.self.query.weight', 'generator.distilbert.transformer.layer.5.sa_layer_norm.bias', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.attention.self.query.weight', 'generator.distilbert.transformer.layer.0.ffn.lin1.weight', 'generator.distilbert.transformer.layer.3.output_layer_norm.weight', 'aux_bert.embeddings.position_embeddings.weight', 'generator.distilbert.transformer.layer.2.attention.out_lin.weight', 'aux_bert.encoder.layer.3.attention.self.key.bias', 'aux_bert.encoder.layer.4.attention.self.value.bias', 'generator.distilbert.transformer.layer.3.attention.v_lin.weight', 'aux_bert.encoder.layer.2.attention.self.key.weight', 'lm_head.decoder.bias', 'generator.distilbert.transformer.layer.1.attention.q_lin.bias', 'aux_bert.encoder.layer.5.output.dense.weight', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.intermediate.dense.weight', 'generator.vocab_projector.weight', 'generator.distilbert.transformer.layer.0.output_layer_norm.bias', 'aux_bert.encoder.layer.9.intermediate.dense.bias', 'mlp.net.3.weight', 'generator.distilbert.transformer.layer.0.attention.v_lin.weight', 'generator.distilbert.transformer.layer.0.sa_layer_norm.bias', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.intermediate.dense.weight', 'aux_bert.encoder.layer.3.attention.self.value.weight', 'generator.distilbert.transformer.layer.3.output_layer_norm.bias', 'aux_bert.encoder.layer.8.attention.output.dense.bias', 'aux_bert.encoder.layer.10.attention.self.key.bias', 'generator.distilbert.transformer.layer.4.ffn.lin2.bias', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.intermediate.dense.weight', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.intermediate.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertModel were not initialized from the model checkpoint at voidism/diffcse-bert-base-uncased-sts and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "06/14/2024 17:08:49 - INFO - coherencecalculator.diffcse.tool -   Use `cls_before_pooler` for DiffCSE models. If you want to use other pooling policy, specify `pooler` argument.\n"
     ]
    }
   ],
   "source": [
    "vecs = VecLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text_sep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file1</td>\n",
       "      <td>This is a sentence. This is a second sentence.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file2</td>\n",
       "      <td>[This is a very good, sentence., This is a sec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    file                                           text_sep\n",
       "0  file1     This is a sentence. This is a second sentence.\n",
       "1  file2  [This is a very good, sentence., This is a sec..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame()\n",
    "a['file'] = ['file1', 'file2']\n",
    "#a['text'] = ['This is a sentence. This is a second sentence.', 'Praise the sentence. All the more, more sentences! One more sentence.']\n",
    "a['text_sep'] = ['This is a sentence. This is a second sentence.', ['This is a very good', 'sentence.', 'This is a second sentence.']]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data completed.\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2985cb4c9a0148c0a7661a1e60c4f4d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cosines...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcb42aea7cd415e8b6ab377ecd0a089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine values created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                        [0.8849942910865943]\n",
       "1    [0.1870761527103686, 0.8849942910865943]\n",
       "Name: sentCoherenceSeq, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsDf2 = timeseries(vecLoader=vecs, inputDf=a, fileCol='file', textCol='text_sep')\n",
    "tsDf2['sentCoherenceSeq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data completed.\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb4760fa5d6e47c5b1b1f48a7802010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cosines...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea8649234954a8aaad9109bae4b8d05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine values created.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>wordCoherenceSeq</th>\n",
       "      <th>wordCoherenceStaticCentroid</th>\n",
       "      <th>wordCoherenceCumulativeCentroid</th>\n",
       "      <th>phraseCoherenceSeq</th>\n",
       "      <th>phraseCoherenceStaticCentroid</th>\n",
       "      <th>phraseCoherenceCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSeq</th>\n",
       "      <th>sentCoherenceStaticCentroid</th>\n",
       "      <th>...</th>\n",
       "      <th>sentCoherenceBertClsCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSentBertSeq</th>\n",
       "      <th>sentCoherenceSentBertStaticCentroid</th>\n",
       "      <th>sentCoherenceSentBertCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSimCSESeq</th>\n",
       "      <th>sentCoherenceSimCSEStaticCentroid</th>\n",
       "      <th>sentCoherenceSimCSECumulativeCentroid</th>\n",
       "      <th>sentCoherenceDiffCSESeq</th>\n",
       "      <th>sentCoherenceDiffCSEStaticCentroid</th>\n",
       "      <th>sentCoherenceDiffCSECumulativeCentroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file1</td>\n",
       "      <td>This is a sentence. This is a second sentence.</td>\n",
       "      <td>[0.10701483740094679, 0.18326868272943234, 0.2...</td>\n",
       "      <td>[0.7299188157136025, 0.6998196240774819, 0.566...</td>\n",
       "      <td>[1.0000000000000002, 0.7439807918894633, 0.721...</td>\n",
       "      <td>[0.8019901222747275]</td>\n",
       "      <td>[0.9492075964389263, 0.9492075964389265]</td>\n",
       "      <td>[1.0000000000000002, 0.9492075964389265]</td>\n",
       "      <td>[0.8849942910865943]</td>\n",
       "      <td>[0.9708229218262704, 0.9708229218262708]</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.000000035952962, 0.994380936397232]</td>\n",
       "      <td>[0.8421]</td>\n",
       "      <td>[0.95971346, 0.9597136]</td>\n",
       "      <td>[1.0000000193354108, 0.9597135445059117]</td>\n",
       "      <td>[0.7818121]</td>\n",
       "      <td>[0.94387823, 0.9438781]</td>\n",
       "      <td>[1.0000000706831291, 0.9438781576371368]</td>\n",
       "      <td>[0.9419352]</td>\n",
       "      <td>[0.985377, 0.98537683]</td>\n",
       "      <td>[1.0000000297838483, 0.9853768671233218]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file2</td>\n",
       "      <td>Praise the sentence. All the more, more senten...</td>\n",
       "      <td>[0.2094029119147472, 0.10701483740094679, 0.44...</td>\n",
       "      <td>[0.4694290144745616, 0.6609754355720199, 0.649...</td>\n",
       "      <td>[1.0000000000000002, 0.7776255242450402, 0.601...</td>\n",
       "      <td>[0.6429609170757998]</td>\n",
       "      <td>[0.9063555916625109, 0.9063555916625109]</td>\n",
       "      <td>[1.0000000000000002, 0.9063555916625109]</td>\n",
       "      <td>[0.6974219520830809]</td>\n",
       "      <td>[0.9212551090992877, 0.9212551090992875]</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9999999929837042, 0.9491567740275544]</td>\n",
       "      <td>[0.347448]</td>\n",
       "      <td>[0.820807, 0.82080686]</td>\n",
       "      <td>[0.9999999858309396, 0.820806926648033]</td>\n",
       "      <td>[0.4594667]</td>\n",
       "      <td>[0.85424423, 0.8542443]</td>\n",
       "      <td>[1.000000045028904, 0.8542443465129437]</td>\n",
       "      <td>[0.7947672]</td>\n",
       "      <td>[0.9473034, 0.9473033]</td>\n",
       "      <td>[1.0000000684705719, 0.947303332949629]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    file                                               text  \\\n",
       "0  file1     This is a sentence. This is a second sentence.   \n",
       "1  file2  Praise the sentence. All the more, more senten...   \n",
       "\n",
       "                                    wordCoherenceSeq  \\\n",
       "0  [0.10701483740094679, 0.18326868272943234, 0.2...   \n",
       "1  [0.2094029119147472, 0.10701483740094679, 0.44...   \n",
       "\n",
       "                         wordCoherenceStaticCentroid  \\\n",
       "0  [0.7299188157136025, 0.6998196240774819, 0.566...   \n",
       "1  [0.4694290144745616, 0.6609754355720199, 0.649...   \n",
       "\n",
       "                     wordCoherenceCumulativeCentroid    phraseCoherenceSeq  \\\n",
       "0  [1.0000000000000002, 0.7439807918894633, 0.721...  [0.8019901222747275]   \n",
       "1  [1.0000000000000002, 0.7776255242450402, 0.601...  [0.6429609170757998]   \n",
       "\n",
       "              phraseCoherenceStaticCentroid  \\\n",
       "0  [0.9492075964389263, 0.9492075964389265]   \n",
       "1  [0.9063555916625109, 0.9063555916625109]   \n",
       "\n",
       "          phraseCoherenceCumulativeCentroid      sentCoherenceSeq  \\\n",
       "0  [1.0000000000000002, 0.9492075964389265]  [0.8849942910865943]   \n",
       "1  [1.0000000000000002, 0.9063555916625109]  [0.6974219520830809]   \n",
       "\n",
       "                sentCoherenceStaticCentroid  ...  \\\n",
       "0  [0.9708229218262704, 0.9708229218262708]  ...   \n",
       "1  [0.9212551090992877, 0.9212551090992875]  ...   \n",
       "\n",
       "     sentCoherenceBertClsCumulativeCentroid sentCoherenceSentBertSeq  \\\n",
       "0    [1.000000035952962, 0.994380936397232]                 [0.8421]   \n",
       "1  [0.9999999929837042, 0.9491567740275544]               [0.347448]   \n",
       "\n",
       "  sentCoherenceSentBertStaticCentroid  \\\n",
       "0             [0.95971346, 0.9597136]   \n",
       "1              [0.820807, 0.82080686]   \n",
       "\n",
       "    sentCoherenceSentBertCumulativeCentroid sentCoherenceSimCSESeq  \\\n",
       "0  [1.0000000193354108, 0.9597135445059117]            [0.7818121]   \n",
       "1   [0.9999999858309396, 0.820806926648033]            [0.4594667]   \n",
       "\n",
       "  sentCoherenceSimCSEStaticCentroid     sentCoherenceSimCSECumulativeCentroid  \\\n",
       "0           [0.94387823, 0.9438781]  [1.0000000706831291, 0.9438781576371368]   \n",
       "1           [0.85424423, 0.8542443]   [1.000000045028904, 0.8542443465129437]   \n",
       "\n",
       "  sentCoherenceDiffCSESeq sentCoherenceDiffCSEStaticCentroid  \\\n",
       "0             [0.9419352]             [0.985377, 0.98537683]   \n",
       "1             [0.7947672]             [0.9473034, 0.9473033]   \n",
       "\n",
       "     sentCoherenceDiffCSECumulativeCentroid  \n",
       "0  [1.0000000297838483, 0.9853768671233218]  \n",
       "1   [1.0000000684705719, 0.947303332949629]  \n",
       "\n",
       "[2 rows x 38 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsDf1 = timeseries(vecLoader=vecs, inputDf=a, fileCol='file', textCol='text')\n",
    "tsDf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.8849942910865943]\n",
       "1    [0.6974219520830809]\n",
       "Name: sentCoherenceSeq, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsDf2['sentCoherenceSeq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputDir = '/edata/coherencenotebook/coherencecalculator/tests/testData'\n",
    "#vecs = VecLoader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data completed.\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58fde063ffbc4874a05d24477f82b129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cosines...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb468e50a27a4d1da2cdc945b05d51ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine values created.\n"
     ]
    }
   ],
   "source": [
    "tsDf = timeseries(vecLoader=None, inputDir=inputDir, vecType='custom', embeddingFunc=lambda x: [[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data completed.\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c97a6f486341a9a555ef2c5d01b0c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cosines...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5246fa4d3a4b0799161738bfe99a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine values created.\n",
      "Generating features...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2e80ed1bf44151910f48deda063a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created.\n",
      "Finalizing coherence scores...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5192fffd7cb24e9c8bfbb7427eba6500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tardisDf = tardis(vecLoader=vecs, inputDir=inputDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>wordCoherenceSeq</th>\n",
       "      <th>wordCoherenceStaticCentroid</th>\n",
       "      <th>wordCoherenceCumulativeCentroid</th>\n",
       "      <th>phraseCoherenceSeq</th>\n",
       "      <th>phraseCoherenceStaticCentroid</th>\n",
       "      <th>phraseCoherenceCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSeq</th>\n",
       "      <th>sentCoherenceStaticCentroid</th>\n",
       "      <th>...</th>\n",
       "      <th>sentCoherenceBertClsCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSentBertSeq</th>\n",
       "      <th>sentCoherenceSentBertStaticCentroid</th>\n",
       "      <th>sentCoherenceSentBertCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSimCSESeq</th>\n",
       "      <th>sentCoherenceSimCSEStaticCentroid</th>\n",
       "      <th>sentCoherenceSimCSECumulativeCentroid</th>\n",
       "      <th>sentCoherenceDiffCSESeq</th>\n",
       "      <th>sentCoherenceDiffCSEStaticCentroid</th>\n",
       "      <th>sentCoherenceDiffCSECumulativeCentroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-2r.txt</td>\n",
       "      <td>Absolutely nothing .. No it's just too much .....</td>\n",
       "      <td>1.797816</td>\n",
       "      <td>1.527181</td>\n",
       "      <td>1.767595</td>\n",
       "      <td>1.388635</td>\n",
       "      <td>1.348795</td>\n",
       "      <td>1.355564</td>\n",
       "      <td>1.344966</td>\n",
       "      <td>1.319623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631745</td>\n",
       "      <td>1.426781</td>\n",
       "      <td>1.328137</td>\n",
       "      <td>1.457939</td>\n",
       "      <td>1.478999</td>\n",
       "      <td>1.474958</td>\n",
       "      <td>1.384949</td>\n",
       "      <td>1.469341</td>\n",
       "      <td>1.430712</td>\n",
       "      <td>1.479486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005-0r.txt</td>\n",
       "      <td>Well it appears that George .... No I can't te...</td>\n",
       "      <td>1.158027</td>\n",
       "      <td>0.906954</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>1.033048</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.834790</td>\n",
       "      <td>0.673147</td>\n",
       "      <td>0.510666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507769</td>\n",
       "      <td>0.557340</td>\n",
       "      <td>0.522490</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.719222</td>\n",
       "      <td>0.859452</td>\n",
       "      <td>0.614131</td>\n",
       "      <td>0.673221</td>\n",
       "      <td>0.736735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005-2r.txt</td>\n",
       "      <td>Okay .. .... Yes .. No .. . okay .. Yeah .. .....</td>\n",
       "      <td>1.487834</td>\n",
       "      <td>1.136380</td>\n",
       "      <td>1.208286</td>\n",
       "      <td>0.924207</td>\n",
       "      <td>0.807346</td>\n",
       "      <td>0.763058</td>\n",
       "      <td>1.135657</td>\n",
       "      <td>0.993181</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197797</td>\n",
       "      <td>1.121282</td>\n",
       "      <td>1.162351</td>\n",
       "      <td>1.198253</td>\n",
       "      <td>1.085853</td>\n",
       "      <td>1.253886</td>\n",
       "      <td>1.169720</td>\n",
       "      <td>1.065330</td>\n",
       "      <td>1.230047</td>\n",
       "      <td>1.190836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007-1r.txt</td>\n",
       "      <td>It had been a long time since uncle Bill had b...</td>\n",
       "      <td>1.324786</td>\n",
       "      <td>0.792585</td>\n",
       "      <td>1.050230</td>\n",
       "      <td>0.814491</td>\n",
       "      <td>0.800689</td>\n",
       "      <td>0.649367</td>\n",
       "      <td>0.650868</td>\n",
       "      <td>0.535699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682807</td>\n",
       "      <td>0.629114</td>\n",
       "      <td>0.641415</td>\n",
       "      <td>0.737231</td>\n",
       "      <td>0.725563</td>\n",
       "      <td>0.684424</td>\n",
       "      <td>0.813206</td>\n",
       "      <td>0.629125</td>\n",
       "      <td>0.787367</td>\n",
       "      <td>0.806073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007-3r.txt</td>\n",
       "      <td>. well the girl is I can't think Melanie .. Me...</td>\n",
       "      <td>1.603288</td>\n",
       "      <td>1.263939</td>\n",
       "      <td>1.455014</td>\n",
       "      <td>1.280770</td>\n",
       "      <td>1.275364</td>\n",
       "      <td>1.170724</td>\n",
       "      <td>1.355104</td>\n",
       "      <td>1.455713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371232</td>\n",
       "      <td>1.166891</td>\n",
       "      <td>1.348780</td>\n",
       "      <td>1.428748</td>\n",
       "      <td>1.327642</td>\n",
       "      <td>1.387412</td>\n",
       "      <td>1.477052</td>\n",
       "      <td>1.506663</td>\n",
       "      <td>1.387949</td>\n",
       "      <td>1.518924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>010-0r.txt</td>\n",
       "      <td>George Henderson he went to go visit his daugh...</td>\n",
       "      <td>1.554277</td>\n",
       "      <td>0.862346</td>\n",
       "      <td>0.670381</td>\n",
       "      <td>0.862373</td>\n",
       "      <td>1.047953</td>\n",
       "      <td>0.816375</td>\n",
       "      <td>0.739023</td>\n",
       "      <td>0.668398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.779989</td>\n",
       "      <td>1.044353</td>\n",
       "      <td>0.828940</td>\n",
       "      <td>0.969591</td>\n",
       "      <td>1.040957</td>\n",
       "      <td>0.984362</td>\n",
       "      <td>0.923402</td>\n",
       "      <td>0.929855</td>\n",
       "      <td>1.014585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>010-2r.txt</td>\n",
       "      <td>Yes there was a man by the name of George Mela...</td>\n",
       "      <td>1.411552</td>\n",
       "      <td>1.124198</td>\n",
       "      <td>1.115361</td>\n",
       "      <td>0.990672</td>\n",
       "      <td>1.078114</td>\n",
       "      <td>0.850215</td>\n",
       "      <td>0.672339</td>\n",
       "      <td>0.536310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715522</td>\n",
       "      <td>0.632546</td>\n",
       "      <td>0.577573</td>\n",
       "      <td>0.757926</td>\n",
       "      <td>0.656224</td>\n",
       "      <td>0.671595</td>\n",
       "      <td>0.770968</td>\n",
       "      <td>0.630990</td>\n",
       "      <td>0.707022</td>\n",
       "      <td>0.756522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>016-0r.txt</td>\n",
       "      <td>Yeah George Miller was asked by his granddaugh...</td>\n",
       "      <td>1.316894</td>\n",
       "      <td>1.012099</td>\n",
       "      <td>1.035083</td>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.879722</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.609753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657605</td>\n",
       "      <td>0.626017</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>0.647719</td>\n",
       "      <td>0.738500</td>\n",
       "      <td>0.808626</td>\n",
       "      <td>0.792247</td>\n",
       "      <td>0.691506</td>\n",
       "      <td>0.555568</td>\n",
       "      <td>0.742174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file                                               text  \\\n",
       "0  001-2r.txt  Absolutely nothing .. No it's just too much .....   \n",
       "1  005-0r.txt  Well it appears that George .... No I can't te...   \n",
       "2  005-2r.txt  Okay .. .... Yes .. No .. . okay .. Yeah .. .....   \n",
       "3  007-1r.txt  It had been a long time since uncle Bill had b...   \n",
       "4  007-3r.txt  . well the girl is I can't think Melanie .. Me...   \n",
       "5  010-0r.txt  George Henderson he went to go visit his daugh...   \n",
       "6  010-2r.txt  Yes there was a man by the name of George Mela...   \n",
       "7  016-0r.txt  Yeah George Miller was asked by his granddaugh...   \n",
       "\n",
       "   wordCoherenceSeq  wordCoherenceStaticCentroid  \\\n",
       "0          1.797816                     1.527181   \n",
       "1          1.158027                     0.906954   \n",
       "2          1.487834                     1.136380   \n",
       "3          1.324786                     0.792585   \n",
       "4          1.603288                     1.263939   \n",
       "5          1.554277                     0.862346   \n",
       "6          1.411552                     1.124198   \n",
       "7          1.316894                     1.012099   \n",
       "\n",
       "   wordCoherenceCumulativeCentroid  phraseCoherenceSeq  \\\n",
       "0                         1.767595            1.388635   \n",
       "1                         0.954455            1.033048   \n",
       "2                         1.208286            0.924207   \n",
       "3                         1.050230            0.814491   \n",
       "4                         1.455014            1.280770   \n",
       "5                         0.670381            0.862373   \n",
       "6                         1.115361            0.990672   \n",
       "7                         1.035083            0.938200   \n",
       "\n",
       "   phraseCoherenceStaticCentroid  phraseCoherenceCumulativeCentroid  \\\n",
       "0                       1.348795                           1.355564   \n",
       "1                       0.992430                           0.834790   \n",
       "2                       0.807346                           0.763058   \n",
       "3                       0.800689                           0.649367   \n",
       "4                       1.275364                           1.170724   \n",
       "5                       1.047953                           0.816375   \n",
       "6                       1.078114                           0.850215   \n",
       "7                       0.879722                           0.884020   \n",
       "\n",
       "   sentCoherenceSeq  sentCoherenceStaticCentroid  ...  \\\n",
       "0          1.344966                     1.319623  ...   \n",
       "1          0.673147                     0.510666  ...   \n",
       "2          1.135657                     0.993181  ...   \n",
       "3          0.650868                     0.535699  ...   \n",
       "4          1.355104                     1.455713  ...   \n",
       "5          0.739023                     0.668398  ...   \n",
       "6          0.672339                     0.536310  ...   \n",
       "7          0.689549                     0.609753  ...   \n",
       "\n",
       "   sentCoherenceBertClsCumulativeCentroid  sentCoherenceSentBertSeq  \\\n",
       "0                                1.631745                  1.426781   \n",
       "1                                0.507769                  0.557340   \n",
       "2                                1.197797                  1.121282   \n",
       "3                                0.682807                  0.629114   \n",
       "4                                1.371232                  1.166891   \n",
       "5                                0.831758                  0.779989   \n",
       "6                                0.715522                  0.632546   \n",
       "7                                0.657605                  0.626017   \n",
       "\n",
       "   sentCoherenceSentBertStaticCentroid  \\\n",
       "0                             1.328137   \n",
       "1                             0.522490   \n",
       "2                             1.162351   \n",
       "3                             0.641415   \n",
       "4                             1.348780   \n",
       "5                             1.044353   \n",
       "6                             0.577573   \n",
       "7                             0.569880   \n",
       "\n",
       "   sentCoherenceSentBertCumulativeCentroid  sentCoherenceSimCSESeq  \\\n",
       "0                                 1.457939                1.478999   \n",
       "1                                 0.720393                0.733700   \n",
       "2                                 1.198253                1.085853   \n",
       "3                                 0.737231                0.725563   \n",
       "4                                 1.428748                1.327642   \n",
       "5                                 0.828940                0.969591   \n",
       "6                                 0.757926                0.656224   \n",
       "7                                 0.647719                0.738500   \n",
       "\n",
       "   sentCoherenceSimCSEStaticCentroid  sentCoherenceSimCSECumulativeCentroid  \\\n",
       "0                           1.474958                               1.384949   \n",
       "1                           0.719222                               0.859452   \n",
       "2                           1.253886                               1.169720   \n",
       "3                           0.684424                               0.813206   \n",
       "4                           1.387412                               1.477052   \n",
       "5                           1.040957                               0.984362   \n",
       "6                           0.671595                               0.770968   \n",
       "7                           0.808626                               0.792247   \n",
       "\n",
       "   sentCoherenceDiffCSESeq  sentCoherenceDiffCSEStaticCentroid  \\\n",
       "0                 1.469341                            1.430712   \n",
       "1                 0.614131                            0.673221   \n",
       "2                 1.065330                            1.230047   \n",
       "3                 0.629125                            0.787367   \n",
       "4                 1.506663                            1.387949   \n",
       "5                 0.923402                            0.929855   \n",
       "6                 0.630990                            0.707022   \n",
       "7                 0.691506                            0.555568   \n",
       "\n",
       "   sentCoherenceDiffCSECumulativeCentroid  \n",
       "0                                1.479486  \n",
       "1                                0.736735  \n",
       "2                                1.190836  \n",
       "3                                0.806073  \n",
       "4                                1.518924  \n",
       "5                                1.014585  \n",
       "6                                0.756522  \n",
       "7                                0.742174  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tardisDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data completed.\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.031951904296875,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 27,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fcdd43512aa46e699fd9de18c1490a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cosines...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03145718574523926,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 108,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7da80e8af2d148058237d4adb29e9daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/108 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine values created.\n",
      "1 file(s) are dropped because they are not long enough to produce any cosine values.\n"
     ]
    }
   ],
   "source": [
    "#If data is csv/pkl/dataframe, file column name and text column name need to be added\n",
    "#For example: \n",
    "# tsDf = timeseries(vecLoader=vecs, inputCsv=path_to_csv, fileCol='IDCOLNAME', textCol='TEXTCOLNAME', saveDir='./timeseriesout.pkl')\n",
    "tsDf = timeseries(vecLoader=vecs, inputDir=inputDir)\n",
    "#print(pd.read_pickle('./timeseriesout.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating features...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03192591667175293,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 36,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db98597e9e64c62af21de6b712e01b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created.\n"
     ]
    }
   ],
   "source": [
    "featureDict = features(vecLoader=vecs, inputTimeseries=tsDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing coherence scores...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.03347206115722656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 36,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b028e8473b784456bb700b013ab9fd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tardisDf = tardis(vecLoader=vecs, inputFeatures=featureDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>text</th>\n",
       "      <th>wordCoherenceSeq</th>\n",
       "      <th>wordCoherenceStaticCentroid</th>\n",
       "      <th>wordCoherenceCumulativeCentroid</th>\n",
       "      <th>phraseCoherenceSeq</th>\n",
       "      <th>phraseCoherenceStaticCentroid</th>\n",
       "      <th>phraseCoherenceCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSeq</th>\n",
       "      <th>sentCoherenceStaticCentroid</th>\n",
       "      <th>...</th>\n",
       "      <th>sentCoherenceBertClsCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSentBertSeq</th>\n",
       "      <th>sentCoherenceSentBertStaticCentroid</th>\n",
       "      <th>sentCoherenceSentBertCumulativeCentroid</th>\n",
       "      <th>sentCoherenceSimCSESeq</th>\n",
       "      <th>sentCoherenceSimCSEStaticCentroid</th>\n",
       "      <th>sentCoherenceSimCSECumulativeCentroid</th>\n",
       "      <th>sentCoherenceDiffCSESeq</th>\n",
       "      <th>sentCoherenceDiffCSEStaticCentroid</th>\n",
       "      <th>sentCoherenceDiffCSECumulativeCentroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001-2r.txt</td>\n",
       "      <td>Absolutely nothing .. No it's just too much .....</td>\n",
       "      <td>1.797816</td>\n",
       "      <td>1.527181</td>\n",
       "      <td>1.767595</td>\n",
       "      <td>1.388635</td>\n",
       "      <td>1.348795</td>\n",
       "      <td>1.355564</td>\n",
       "      <td>1.344966</td>\n",
       "      <td>1.319623</td>\n",
       "      <td>...</td>\n",
       "      <td>1.631745</td>\n",
       "      <td>1.426781</td>\n",
       "      <td>1.328137</td>\n",
       "      <td>1.457939</td>\n",
       "      <td>1.478999</td>\n",
       "      <td>1.474958</td>\n",
       "      <td>1.384949</td>\n",
       "      <td>1.469341</td>\n",
       "      <td>1.430712</td>\n",
       "      <td>1.479486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>005-0r.txt</td>\n",
       "      <td>Well it appears that George .... No I can't te...</td>\n",
       "      <td>1.158027</td>\n",
       "      <td>0.906954</td>\n",
       "      <td>0.954455</td>\n",
       "      <td>1.033048</td>\n",
       "      <td>0.992430</td>\n",
       "      <td>0.834790</td>\n",
       "      <td>0.673147</td>\n",
       "      <td>0.510666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507769</td>\n",
       "      <td>0.557340</td>\n",
       "      <td>0.522490</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.719222</td>\n",
       "      <td>0.859452</td>\n",
       "      <td>0.614131</td>\n",
       "      <td>0.673221</td>\n",
       "      <td>0.736735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>005-2r.txt</td>\n",
       "      <td>Okay .. .... Yes .. No .. . okay .. Yeah .. .....</td>\n",
       "      <td>1.487834</td>\n",
       "      <td>1.136380</td>\n",
       "      <td>1.208286</td>\n",
       "      <td>0.924207</td>\n",
       "      <td>0.807346</td>\n",
       "      <td>0.763058</td>\n",
       "      <td>1.135657</td>\n",
       "      <td>0.993181</td>\n",
       "      <td>...</td>\n",
       "      <td>1.197797</td>\n",
       "      <td>1.121282</td>\n",
       "      <td>1.162351</td>\n",
       "      <td>1.198253</td>\n",
       "      <td>1.085853</td>\n",
       "      <td>1.253886</td>\n",
       "      <td>1.169720</td>\n",
       "      <td>1.065330</td>\n",
       "      <td>1.230047</td>\n",
       "      <td>1.190836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007-1r.txt</td>\n",
       "      <td>It had been a long time since uncle Bill had b...</td>\n",
       "      <td>1.324786</td>\n",
       "      <td>0.792585</td>\n",
       "      <td>1.050230</td>\n",
       "      <td>0.814491</td>\n",
       "      <td>0.800689</td>\n",
       "      <td>0.649367</td>\n",
       "      <td>0.650868</td>\n",
       "      <td>0.535699</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682807</td>\n",
       "      <td>0.629114</td>\n",
       "      <td>0.641415</td>\n",
       "      <td>0.737231</td>\n",
       "      <td>0.725563</td>\n",
       "      <td>0.684424</td>\n",
       "      <td>0.813206</td>\n",
       "      <td>0.629125</td>\n",
       "      <td>0.787367</td>\n",
       "      <td>0.806073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007-3r.txt</td>\n",
       "      <td>. well the girl is I can't think Melanie .. Me...</td>\n",
       "      <td>1.603288</td>\n",
       "      <td>1.263939</td>\n",
       "      <td>1.455014</td>\n",
       "      <td>1.280770</td>\n",
       "      <td>1.275364</td>\n",
       "      <td>1.170724</td>\n",
       "      <td>1.355104</td>\n",
       "      <td>1.455713</td>\n",
       "      <td>...</td>\n",
       "      <td>1.371232</td>\n",
       "      <td>1.166891</td>\n",
       "      <td>1.348780</td>\n",
       "      <td>1.428748</td>\n",
       "      <td>1.327642</td>\n",
       "      <td>1.387412</td>\n",
       "      <td>1.477052</td>\n",
       "      <td>1.506663</td>\n",
       "      <td>1.387949</td>\n",
       "      <td>1.518924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>010-0r.txt</td>\n",
       "      <td>George Henderson he went to go visit his daugh...</td>\n",
       "      <td>1.554277</td>\n",
       "      <td>0.862346</td>\n",
       "      <td>0.670381</td>\n",
       "      <td>0.862373</td>\n",
       "      <td>1.047953</td>\n",
       "      <td>0.816375</td>\n",
       "      <td>0.739023</td>\n",
       "      <td>0.668398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831758</td>\n",
       "      <td>0.779989</td>\n",
       "      <td>1.044353</td>\n",
       "      <td>0.828940</td>\n",
       "      <td>0.969591</td>\n",
       "      <td>1.040957</td>\n",
       "      <td>0.984362</td>\n",
       "      <td>0.923402</td>\n",
       "      <td>0.929855</td>\n",
       "      <td>1.014585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>010-2r.txt</td>\n",
       "      <td>Yes there was a man by the name of George Mela...</td>\n",
       "      <td>1.411552</td>\n",
       "      <td>1.124198</td>\n",
       "      <td>1.115361</td>\n",
       "      <td>0.990672</td>\n",
       "      <td>1.078114</td>\n",
       "      <td>0.850215</td>\n",
       "      <td>0.672339</td>\n",
       "      <td>0.536310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.715522</td>\n",
       "      <td>0.632546</td>\n",
       "      <td>0.577573</td>\n",
       "      <td>0.757926</td>\n",
       "      <td>0.656224</td>\n",
       "      <td>0.671595</td>\n",
       "      <td>0.770968</td>\n",
       "      <td>0.630990</td>\n",
       "      <td>0.707022</td>\n",
       "      <td>0.756522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>016-0r.txt</td>\n",
       "      <td>Yeah George Miller was asked by his granddaugh...</td>\n",
       "      <td>1.316894</td>\n",
       "      <td>1.012099</td>\n",
       "      <td>1.035083</td>\n",
       "      <td>0.938200</td>\n",
       "      <td>0.879722</td>\n",
       "      <td>0.884020</td>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.609753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657605</td>\n",
       "      <td>0.626017</td>\n",
       "      <td>0.569880</td>\n",
       "      <td>0.647719</td>\n",
       "      <td>0.738500</td>\n",
       "      <td>0.808626</td>\n",
       "      <td>0.792247</td>\n",
       "      <td>0.691506</td>\n",
       "      <td>0.555568</td>\n",
       "      <td>0.742174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         file                                               text  \\\n",
       "0  001-2r.txt  Absolutely nothing .. No it's just too much .....   \n",
       "1  005-0r.txt  Well it appears that George .... No I can't te...   \n",
       "2  005-2r.txt  Okay .. .... Yes .. No .. . okay .. Yeah .. .....   \n",
       "3  007-1r.txt  It had been a long time since uncle Bill had b...   \n",
       "4  007-3r.txt  . well the girl is I can't think Melanie .. Me...   \n",
       "5  010-0r.txt  George Henderson he went to go visit his daugh...   \n",
       "6  010-2r.txt  Yes there was a man by the name of George Mela...   \n",
       "7  016-0r.txt  Yeah George Miller was asked by his granddaugh...   \n",
       "\n",
       "   wordCoherenceSeq  wordCoherenceStaticCentroid  \\\n",
       "0          1.797816                     1.527181   \n",
       "1          1.158027                     0.906954   \n",
       "2          1.487834                     1.136380   \n",
       "3          1.324786                     0.792585   \n",
       "4          1.603288                     1.263939   \n",
       "5          1.554277                     0.862346   \n",
       "6          1.411552                     1.124198   \n",
       "7          1.316894                     1.012099   \n",
       "\n",
       "   wordCoherenceCumulativeCentroid  phraseCoherenceSeq  \\\n",
       "0                         1.767595            1.388635   \n",
       "1                         0.954455            1.033048   \n",
       "2                         1.208286            0.924207   \n",
       "3                         1.050230            0.814491   \n",
       "4                         1.455014            1.280770   \n",
       "5                         0.670381            0.862373   \n",
       "6                         1.115361            0.990672   \n",
       "7                         1.035083            0.938200   \n",
       "\n",
       "   phraseCoherenceStaticCentroid  phraseCoherenceCumulativeCentroid  \\\n",
       "0                       1.348795                           1.355564   \n",
       "1                       0.992430                           0.834790   \n",
       "2                       0.807346                           0.763058   \n",
       "3                       0.800689                           0.649367   \n",
       "4                       1.275364                           1.170724   \n",
       "5                       1.047953                           0.816375   \n",
       "6                       1.078114                           0.850215   \n",
       "7                       0.879722                           0.884020   \n",
       "\n",
       "   sentCoherenceSeq  sentCoherenceStaticCentroid  ...  \\\n",
       "0          1.344966                     1.319623  ...   \n",
       "1          0.673147                     0.510666  ...   \n",
       "2          1.135657                     0.993181  ...   \n",
       "3          0.650868                     0.535699  ...   \n",
       "4          1.355104                     1.455713  ...   \n",
       "5          0.739023                     0.668398  ...   \n",
       "6          0.672339                     0.536310  ...   \n",
       "7          0.689549                     0.609753  ...   \n",
       "\n",
       "   sentCoherenceBertClsCumulativeCentroid  sentCoherenceSentBertSeq  \\\n",
       "0                                1.631745                  1.426781   \n",
       "1                                0.507769                  0.557340   \n",
       "2                                1.197797                  1.121282   \n",
       "3                                0.682807                  0.629114   \n",
       "4                                1.371232                  1.166891   \n",
       "5                                0.831758                  0.779989   \n",
       "6                                0.715522                  0.632546   \n",
       "7                                0.657605                  0.626017   \n",
       "\n",
       "   sentCoherenceSentBertStaticCentroid  \\\n",
       "0                             1.328137   \n",
       "1                             0.522490   \n",
       "2                             1.162351   \n",
       "3                             0.641415   \n",
       "4                             1.348780   \n",
       "5                             1.044353   \n",
       "6                             0.577573   \n",
       "7                             0.569880   \n",
       "\n",
       "   sentCoherenceSentBertCumulativeCentroid  sentCoherenceSimCSESeq  \\\n",
       "0                                 1.457939                1.478999   \n",
       "1                                 0.720393                0.733700   \n",
       "2                                 1.198253                1.085853   \n",
       "3                                 0.737231                0.725563   \n",
       "4                                 1.428748                1.327642   \n",
       "5                                 0.828940                0.969591   \n",
       "6                                 0.757926                0.656224   \n",
       "7                                 0.647719                0.738500   \n",
       "\n",
       "   sentCoherenceSimCSEStaticCentroid  sentCoherenceSimCSECumulativeCentroid  \\\n",
       "0                           1.474958                               1.384949   \n",
       "1                           0.719222                               0.859452   \n",
       "2                           1.253886                               1.169720   \n",
       "3                           0.684424                               0.813206   \n",
       "4                           1.387412                               1.477052   \n",
       "5                           1.040957                               0.984362   \n",
       "6                           0.671595                               0.770968   \n",
       "7                           0.808626                               0.792247   \n",
       "\n",
       "   sentCoherenceDiffCSESeq  sentCoherenceDiffCSEStaticCentroid  \\\n",
       "0                 1.469341                            1.430712   \n",
       "1                 0.614131                            0.673221   \n",
       "2                 1.065330                            1.230047   \n",
       "3                 0.629125                            0.787367   \n",
       "4                 1.506663                            1.387949   \n",
       "5                 0.923402                            0.929855   \n",
       "6                 0.630990                            0.707022   \n",
       "7                 0.691506                            0.555568   \n",
       "\n",
       "   sentCoherenceDiffCSECumulativeCentroid  \n",
       "0                                1.479486  \n",
       "1                                0.736735  \n",
       "2                                1.190836  \n",
       "3                                0.806073  \n",
       "4                                1.518924  \n",
       "5                                1.014585  \n",
       "6                                0.756522  \n",
       "7                                0.742174  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tardisDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coherencepip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
